operation_mode: chain_eqe


model:
  framework: 'torch' 
  model_type : ssd
  # model_name options for SSD model 
  # ['ssd_mobilenetv1_pt', 'ssdlite_mobilenetv1_pt', 'ssd_mobilenetv2_pt', 'ssdlite_mobilenetv2_pt', 'ssdlite_mobilenetv3small_pt', 'ssdlite_mobilenetv3large_pt']
  model_name: "ssdlite_mobilenetv3small_pt"
  width_mult: 1.0
  pretrained: True
  # dataset name coco_person is for pretrained dataset coco_person
  pretrained_dataset : coco_person
  input_shape: [3, 300, 300]
  num_classes: 1


dataset:
  format : coco
  dataset_name: coco
  class_names : ["person"]
  num_workers: 8
  training_path : "" # not used
  # make sure that only one class is present in this json (person)
  test_images_path : ./datasets/coco/val2017
  test_annotations_path: ./datasets/coco/annotations/instances_val2017_person.json # annotation file json 
  quantization_split: 0.01 
  quantization_path : ./datasets/coco/val2017
  
# ---------------- preprocessing Configuration ---------------- #
preprocessing: 
  mean :  [127, 127, 127]
  std : 128.0
  rescaling:
    scale  : 1
    offset : 0 
  resizing:
      aspect_ratio: fit
      interpolation: nearest
  color_mode: rgb

# ---------------- postrocessing Configuration ---------------- #
postprocessing:
  confidence_thresh: 0.001
  NMS_thresh: 0.5
  IoU_eval_thresh: 0.45
  plot_metrics: False #True   # Plot precision versus recall curves. Default is False.
  max_detection_boxes: 500

# ---------------- quantization Configuration ---------------- #
quantization:
  quantizer: onnx_quantizer
  target_opset: 17
  granularity: per_channel #per_channel
  quantization_type: PTQ
  quantization_input_type: float 
  quantization_output_type: float
  export_dir: quantized_models

mlflow:
  uri: ./pt/src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./pt/src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}
