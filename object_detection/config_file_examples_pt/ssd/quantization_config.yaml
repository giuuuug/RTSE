operation_mode: quantization

general:
  saved_models_dir: ssd_mobilenetv1_pt           
  global_seed: 42

model:
  framework: 'torch' 
  model_type : ssd
  # model_name options for SSD model 
  # ['ssd_mobilenetv1_pt', 'ssdlite_mobilenetv1_pt', 'ssd_mobilenetv2_pt', 'ssdlite_mobilenetv2_pt', 'ssdlite_mobilenetv3small_pt', 'ssdlite_mobilenetv3large_pt']
  model_name: "ssdlite_mobilenetv3small_pt"
  width_mult: 1.0
  pretrained: True
  pretrained_dataset : "voc"
  input_shape: [3, 300, 300]
  num_classes: 20
  
dataset:
  format : 'voc'
  dataset_name: "voc"
  class_names: [
            'aeroplane', 'bicycle', 'bird', 'boat',
            'bottle', 'bus', 'car', 'cat', 'chair',
            'cow', 'diningtable', 'dog', 'horse',
            'motorbike', 'person', 'pottedplant',
            'sheep', 'sofa', 'train', 'tvmonitor']
  num_workers: 4
  quantization_split: 0.01 
  quantization_path : ./datasets/VOCdevkit/VOC2007/JPEGImages/

# ---------------- preprocessing Configuration ---------------- #
preprocessing: 
  mean :  [127, 127, 127]
  std : 128.0
  rescaling:
    scale  : 1
    offset : 0 
  resizing:
      aspect_ratio: fit
      interpolation: nearest
  color_mode: rgb

# ---------------- postprocessing Configuration ---------------- #
postprocessing: # 
  confidence_thresh: 0.01
  NMS_thresh: 0.50
  IoU_eval_thresh: 0.5 
  max_detection_boxes: 100

# ---------------- quantization Configuration ---------------- #
quantization:
  quantizer: Onnx_quantizer
  quantization_type: PTQ
  quantization_input_type: uint8
  quantization_output_type: float
  export_dir: quantized_models

mlflow:
  uri: ./pt/src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./pt/src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}