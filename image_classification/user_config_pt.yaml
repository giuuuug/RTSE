general:
  project_name: '' 
  output: '' 
  saved_models_dir: saved_models
  
  display_figures: False 
  seed: 42 
  gpu_memory_limit: 3 
  workers: 4 
  log_interval: 50
  recovery_interval: 0
  checkpoint_hist: 10
  save_images: False
  amp: false
  amp_dtype: "float16"
  amp_impl: "native"
  no_ddp_bb: false
  synchronize_step: false
  pin_mem: false 
  no_prefetcher: true
  eval_metric: "top1"
  tta: 0
  local_rank: 0
  use_multi_epochs_loader: false
  log_wandb: false
  log_tb: false

operation_mode: training 

# quantization:
#    quantizer: Onnx_quantizer
#    quantization_type: PTQ
#    quantization_input_type: uint8
#    quantization_output_type: float
#    export_dir: quantized_models

dataset:
  dataset_name: "imagenet" # options "flowers102", "food101", "imagenet"
  class_names: '' # how is class_names used, torch especially imagenet requires a dict called class_map
  classes_file_path: ./datasets/deployment_labels_imagenet.txt
  num_classes: 1000 # change according to your dataset
  data_dir: 'local/datasets/' # provide root folder which cotnains imagenet folder and this can also be used for quantization as a fall back
  #train_split: "train" # folder name under root (for imagenet) Optional for standard imagenet
  #val_split: "validation" # folder name under root (for imagenet) Optional for standard imagenet
  #test_path: '/local/datasets/ic_imagenet_2012/val/'
  #quantization_path: '/local/datasets/ic_imagenet_2012/val/'
  #prediction_path: '/local/datasets/ic_imagenet_2012/n01440764/'
   
preprocessing: 
  rescaling:
    scale: 1/255.0 # TODO scale node is already present under data_augmentation
    offset: 0
  resizing:
    interpolation: nearest # nearest 'Image resize interpolation type (overrides model)'
    aspect_ratio: fit
  color_mode: rgb
  mean: [0.485, 0.456, 0.406] # 'Override mean pixel value of dataset'
  std: [0.229, 0.224, 0.225] # 'Override std deviation of dataset'

data_augmentation:
  no_aug: False  
  scale: [0.08, 1.0] # TODO scale node is already present under data_augmentation
  ratio: [0.75, 1.33]
  horizontal_flip: 0.5
  vertical_flip: 0.0
  hflip: 0.5
  vflip: 0.0
  color_jitter: 0.4
  aa: null 
  aug_repeats: 0
  aug_splits: 0
  jsd_loss: False
  bce_loss: False
  bce_target_thresh: null
  reprob: 0 
  remode: 'pixel' 
  recount: 1 
  resplit: False  
  mixup: 0.0
  cutmix: 0.0
  cutmix_minmax: null  # Example: [0.3, 0.8]
  mixup_prob: 1.0
  mixup_switch_prob: 0.5
  mixup_mode: "batch"
  smoothing: 0.1
  train_interpolation: "random"
  drop: 0.0
  drop_connect: null
  drop_path: null
  drop_block: null

model: 
  model_name: 'mobilenetv2_w035_pt' 
  pretrained: True
  pretrained_dataset: "imagenet"
  input_shape: [3, 224, 224]

training:
  epochs: 2
  batch_size: 256
  validation_batch_size: null

  optimizer:
    opt: 'sgd' 
    opt-eps: null 
    opt-betas: null 
    momentum: 0.9
    weight_decay: !!float 2e-5
    clip_grad: null
    clip_mode: 'norm'
    layer_decay: null

  lr_scheduler:
    sched: 'cosine'
    sched_on_updates: False
    lr: null
    lr_base: 0.1
    lr_base_size: 256
    lr_base_scale: ''
    lr_noise: null
    lr_noise_pct: 0.67
    lr_noise_std: 1.0
    lr_cycle_mul: 1.0
    lr_cycle_decay: 0.5
    lr_cycle_limit: 1
    lr_k_decay: 1.0
    warmup_lr: !!float 1e-5
    min_lr: 0
    epoch_repeats: 0
    start_epoch: 0
    decay_milestones: [90, 180, 270]
    decay_epochs: 90 
    warmup_epochs: 5
    warmup_prefix: False
    cooldown_epochs: 0
    patience_epochs: 10
    decay_rate: 0.1

  bn_momentum: null
  bn_eps: null
  sync_bn: false
  dist_bn: "reduce"
  split_bn: false
  #distributed: True

  model_ema: false
  model_ema_force_cpu: false
  model_ema_decay: 0.9998
  worker_seeding: all

mlflow:
  uri: ./pt/src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./pt/src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}