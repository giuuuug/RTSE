general:
  project_name: tf_flowers 
  logs_dir: logs
  saved_models_dir: saved_models
  display_figures: True
  global_seed: 123
  gpu_memory_limit: 24

operation_mode: training
#choices=['training' , 'evaluation', 'prediction', 'deployment', 'quantization', 'benchmarking',
#        'chain_tqeb','chain_tqe','chain_eqe','chain_qb','chain_eqeb','chain_qd ']
model : 
  model_path:
  model_name: mobilenetv2_a100
  model_type: 
  input_shape: (224, 224, 3) # Optional, default value is (224, 224, 3)
  pretrained: True # Optional, use it                     

dataset:
  dataset_name: tf_flowers
  class_names: [daisy, dandelion, roses, sunflowers, tulips]  # Or, classes_file_path, one of it is mandatory for deployment and prediction.
  training_path: ./datasets/flower_photos  # Mandatory
  validation_path:        # Optional
  validation_split: 0.2   # Optional, default value is 0.2
  test_path:              # Optional
  quantization_path:      # Optional
  quantization_split:     # Optional
  check_image_files: False  # Optional, set it to True if you want to check that all the image files can be read successfully
  seed: 127               # Optional, there is a default seed

preprocessing:
  rescaling: { scale: 1/127.5, offset: -1 }
  resizing:
    interpolation: nearest
    aspect_ratio: fit
  color_mode: rgb

data_augmentation:    # Optional section
  random_periodic_resizing:
    image_sizes: [[224,224],[128,128],[256,256]]
  random_contrast:
    factor: 0.4
  random_brightness:
    factor: 0.05
  random_flip:
    mode: horizontal
  random_translation:
    width_factor: 0.25
    height_factor: 0.25
    fill_mode: reflect
    interpolation: nearest
  random_rotation:
    factor: 0.125
    fill_mode: reflect
    interpolation: nearest
  random_zoom:
    width_factor: 0.25
    height_factor: 0.25
    fill_mode: reflect
    interpolation: nearest
  random_shear:
    factor: 0.0515
    fill_mode: wrap
    interpolation: nearest
#  random_gaussian_noise:
#    stddev: (0.0001, 0.005)

training:
  frozen_layers: None  #(0:-1)            # Optional, use if you want to freeze some layers (by default all layers are trainable)
  resume_training_from:  # True when the model_path points on latent model under training like : experiments_outputs/2023_10_26_18_36_09/saved_models/last_augmented_model.keras
                         # False (default) in normal case
  dropout: 0.6                    # Optional, use it if you want a dropout layer to be included in the model
  batch_size: 24
  epochs: 2
  optimizer:
    Adam:
      learning_rate: 0.001
  callbacks:          # Optional section
    ReduceLROnPlateau:
      monitor: val_accuracy
      mode: max
      factor: 0.5
      patience: 40
      min_lr: 1.0e-05
    # LRWarmupCosineDecay:
    #   initial_lr: 0.0001
    #   warmup_steps: 100
    #   max_lr: 0.005
    #   hold_steps: 100
    #   decay_steps: 800
    #   end_lr: 5.0e-05
    EarlyStopping:
      monitor: val_accuracy
      mode: max
      restore_best_weights: true
      patience: 60

quantization:
  quantizer: TFlite_converter
  quantization_type: PTQ
  quantization_input_type: uint8
  quantization_output_type: float
  granularity: per_channel   #per_tensor
  optimize: False   #can be True if per_tensor
  export_dir: quantized_models

tools:
  stedgeai:
    optimization: balanced
    on_cloud: True
    path_to_stedgeai: C:/ST/STEdgeAI/<x.y>/Utilities/windows/stedgeai.exe
  path_to_cubeIDE: C:/ST/STM32CubeIDE_<*.*.*>/STM32CubeIDE/stm32cubeide.exe

benchmarking:
  board: STM32H747I-DISCO

deployment:
  c_project_path: ../application_code/image_classification/STM32N6
  IDE: GCC
  verbosity: 1
  hardware_setup:
    serie: STM32H7
    board: STM32H747I-DISCO

mlflow:
  uri: ./tf/src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./tf/src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}
