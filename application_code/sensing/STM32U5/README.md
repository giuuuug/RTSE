# Sensing and Audio Getting Started Package

This project provides an STM32U5 Microcontroler embedded real time environement
to execute [ST Edge AI](https://www.st.com/en/development-tools/stedgeai-core.html)
generated model targetting audio applications. The purpose of this package is to
stream physical data acquired by sensors into a processing chain including a
preprocessing step that typically would perform a first level of feature
extraction, the machine learning inference itself before exposing the results
to the user in real time through a serial console.
The project implements only a bare metal versions.

## Table of Contents

- [Sensing and Audio Getting Started Package](#sensing-and-audio-getting-started-package)
  - [Table of Contents](#table-of-contents)
  - [Hardware Support](#hardware-support)
  - [Tools Version](#tools-version)
  - [Generate C code from tflite file](#generate-c-code-from-tflite-file)
  - [Serial port configuration](#serial-port-configuration)
  - [Typical Output on uart console](#typical-output-on-uart-console)
  - [Configuration](#configuration)
    - [Application](#application)
    - [AED example](#aed-example)
  - [How to update my project with a new version of ST Edge AI](#how-to-update-my-project-with-a-new-version-of-st-edge-ai)
  - [History](#history)
    - [V1.0.0 Initial version](#v100-initial-version)

## Hardware Support

This example runs on [B-U585I-IOT02A](https://www.st.com/en/evaluation-tools/b-u585i-iot02a.html)

## Tools Version

- [STM32CubeIDE](https://www.st.com/content/st_com/en/products/development-tools/software-development-tools/stm32-software-development-tools/stm32-ides/stm32cubeide.html) (__v1.17.0__)
- [STM32CubeProgrammer](https://www.st.com/en/development-tools/stm32cubeprog.html) (__v2.18.0__)
- [STEdgeAI](https://www.st.com/en/development-tools/stedgeai-core.html) (__v3.0.0__)

## Generate C code from tflite file

This repo provide an example of an AI C-model generated by stedgeai: [yamnet_e256_64x96_tl_int8.tflite](ST_Edge_AI/App/yamnet_e256_64x96_tl_int8.tflite)

This application is a C-based project required by the deployment service in the [ModelZoo](https://github.com/STMicroelectronics/stm32ai-modelzoo-services/tree/main). The ModelZoo enables you to train, evaluate, and automatically deploy any supported model.

To deploy your model using the ModelZoo, depending on the user case refer to :
- [Deployment README AED for STM32U5](https://github.com/STMicroelectronics/stm32ai-modelzoo-services/blob/main/audio_event_detection/docs/README_DEPLOYMENT.md)
- [Deployment README HAR for STM32U5](https://github.com/STMicroelectronics/stm32ai-modelzoo-services/blob/main/human_activity_recognition/docs/README_DEPLOYMENT.md)

## Serial port configuration

This package outputs results and useful information (depending on the configured
level of verbosity) through a serial connection. The default configuration of
the serial link is:

- Speed = 115200 bauds
- Data = 8 bit
- Parity = None
- Stop bit = 1 bit
- Flow control = none

## Typical Output on uart console

The welcome screen will display the system configuration and the status of the
audio processing:

```Terminal
---------------------------------------------------------------
        System configuration (Bare Metal)
---------------------------------------------------------------

Log Level: Info

Compiled with IAR 9 (build 318)
STM32 device configuration...
 Device       : DevID:0x042a (UNKNOWN) RevID:0x1000
 Core Arch.   : M33 - FPU  used
 HAL version  : 0x01030005
 SYSCLK clock : 96 MHz
 HCLK clock   : 96 MHz


HSP Acceleration used for Preprocessing

---------------------------------------------------------------


ST.AI RT
---------------------------------------------------------------
 tools version   : v3.1.0
 network rt lib  : v11.1.0-188a7aea
   compiled with : IAR 9 (build 261)

Network informations...
 model signature : 0x090a9f9c7eb32c59dd460d0e4e863094
 c-name          : network
 c-signature     : 0
 c-datetime      : 2025-09-16T09:44:19+0200
 c-compile-time  : Sep 17 2025 14:58:43
 macc            : 23927578
 runtime version : 11.1.0
 n_inputs : 1 (allocate-inputs)
  i[0]  (1,96,64,1) i8(7.0) (fmt=0x00840440) @0x2000D014/6144
        scale=0.058037 zeropoint=31
 n_outputs : 1 (allocate-outputs)
  o[0]  (1,5) float32 (fmt=0x00821040) @0x200003DC/20
 n_activations : 1
  a[0]  u8(8.0) @0x200003D4/101440
 n_states : 0
 n_weights : 1 (allocate-weights)
  w[0]  u8(8.0) @0x200003D4/137876
MEL spectrogram 64 mel x 96 col
- sampling freq : 16000 Hz
- acq period    : 960 ms
- window length : 400 samples
- hop length    : 160 samples

---------------------------------------------------------------
# Start Processing
---------------------------------------------------------------
| Vu meter          | Time(s) |  Cpu  |  Pre  |  AI   | Post  |
                    | 4       | 14.33%|  1.66%| 12.67%|  0.00%|
```

When the signal level is above a certain threshold, the following types of audio
events can be detected:

- chirping_birds
- clapping
- crying_baby
- dog
- rooster

You can play sound samples corresponding to these events to test the system.

Various useful information are displayed on the console such as cpu spent for AI
infering or preprocessing.
A small "Vu Meter" is provided to visualize the audio input level.

The latest detected class is shown along with the time stamp and the probability
of each class is also shown, in a blind way, without class labels.

```Terminal

---------------------------------------------------------------
# Start Processing
---------------------------------------------------------------
| Vu meter          | Time(s) |  Cpu  |  Pre  |  AI   | Post  |
                    | 92      | 13.01%|  1.53%| 11.47%|  0.00%|

               "clapping" detected after 92 s
---------------------------------------------------------------
 0 97  0  1  0
```

Once you have verified the system is working as expected, you can stop the
application by hitting any key on the console and check real time statistics.

```Terminal
---------------------------------------------------------------
# Stop Processing
---------------------------------------------------------------

                       CPU timing summary
---------------------------------------------------------------
| Statistics                  | Pre-Processing | AI inference |
---------------------------------------------------------------
| Number of call              |             543|           347|
| Average (ms)                |           16.61|        126.83|
| Relative load (%)           |            0.22|          1.05|
---------------------------------------------------------------
```

## Configuration

The user has the possibility to override the default application configuration
by altering  `Core/Inc/app_config.h`, and the
AI model by modifying `Dpu/Inc/ai_model_config.h`.

### Application

In  `Core/Inc/app_config.h`,you can change
the default verbosity of the application by setting the `LOG_LEVEL`:

```C
#define LOG_LEVEL LOG_INFO
```

You migth also want to adapt the serial link baud rate:

```C
#define USE_UART_BAUDRATE 115200
```

### AED example

The example provided below is based on Yamnet 256 model provided in the
[ST model zoo](https://github.com/STMicroelectronics/stm32ai-modelzoo).

In `Dpu/Inc/ai_model_config.h`, first describes the
number and the nature of the model output and its type:

```C
#define CTRL_X_CUBE_AI_MODEL_NB_OUTPUT         (1U)
#define CTRL_X_CUBE_AI_MODEL_OUTPUT_1          (CTRL_AI_CLASS_DISTRIBUTION)
```

Then you describe the class indexes and their labels in this way:

```C
#define CTRL_X_CUBE_AI_MODEL_CLASS_NUMBER        (5U)
#define CTRL_X_CUBE_AI_MODEL_CLASS_LIST          {"chirping_birds","clapping",\
                                                  "crying_baby","dog","rooster"}
```

Now you can select audio preprocessing type:

```C
#define CTRL_X_CUBE_AI_PREPROC                 (CTRL_AI_SPECTROGRAM_LOG_MEL)
```

For spectrogram log mel pre processing you can specify the various parameters of
the patch processing:

![single network configuration](_htmresc/AudioPatchProcessing.svg)

The parameters are:

```C
#define CTRL_X_CUBE_AI_SPECTROGRAM_NMEL          (64U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_COL           (96U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_HOP_LENGTH    (160U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_NFFT          (512U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_WINDOW_LENGTH (400U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_NORMALIZE     (0U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_FORMULA       (MEL_HTK)
#define CTRL_X_CUBE_AI_SPECTROGRAM_FMIN          (125U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_FMAX          (7500U)
#define CTRL_X_CUBE_AI_SPECTROGRAM_TYPE          (SPECTRUM_TYPE_MAGNITUDE)
#define CTRL_X_CUBE_AI_SPECTROGRAM_LOG_FORMULA   (LOGMELSPECTROGRAM_SCALE_LOG)
```

For optimizing Mel Spectrogram computational performances the following *L*ook
*U*p *T*ables (*LUT*) needs to be provided:

- the smoothing window to be applied before the Fast Fourrier transform , this
is typically an Hanning window the table is named with the following defines:

```C
#define CTRL_X_CUBE_AI_SPECTROGRAM_WIN           (user_win)
```

- the Mel filters taps. Only non nul taps are provided in a concatenated form,
which is why start and stop indexes are provided in separated tables

```C
#define CTRL_X_CUBE_AI_SPECTROGRAM_MEL_LUT       (user_melFiltersLut)
#define CTRL_X_CUBE_AI_SPECTROGRAM_MEL_START_IDX (user_melFilterStartIndices)
#define CTRL_X_CUBE_AI_SPECTROGRAM_MEL_STOP_IDX  (user_melFilterStopIndices)
```

Typically, *LUT*s can be generated by the ST model zoo deployment script.
Alternatively python scripts are provided in
`<getting-start-install-dir>/Utils/GenHeader`.

These *LUT*s are defined in
`<getting-start-install-dir>/Dpu/Src/user_mel_tables.c` and declared in
`<getting-start-install-dir>/Dpu/Inc/user_mel_tables.h`

You will now describe the digital microphone that will connect to the AI
processing chain:

```C
#define CTRL_X_CUBE_AI_SENSOR_TYPE            (COM_TYPE_MIC)
#define CTRL_X_CUBE_AI_SENSOR_ODR             (16000.0F)
```
## How to update my project with a new version of ST Edge AI

The neural network model files (`network.c/h`, etc.) included in this project were generated using [STEdgeAI](https://www.st.com/en/development-tools/stedgeai-core.html) version 3.0.0.

If you use a different version of STEdgeAI to generate these model files, please follow the STEdgeAI instructions on [How to update my project with a new version of ST Edge AI Core](https://stedgeai-dc.st.com/assets/embedded-docs/stneuralart_faqs_update_version.html) to update your project.

## History

### V1.0.0 Initial version

* Initial version: bare metal appli supporting AED and HAR.
* Limited to CubeIDE / arm gcc toolchain
