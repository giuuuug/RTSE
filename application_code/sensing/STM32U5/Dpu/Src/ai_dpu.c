/**
  ******************************************************************************
  * @file    ai_dpu.c
  * @author  MCD Application Team
  * @brief   This file is implementing ai processing functions that are making
  * 		 use of libraries generated by X-CUBE-AI
  * @version $Version$
  * @date    $Date$
  ******************************************************************************
  * @attention
  *
  * Copyright (c) 2025 STMicroelectronics.
  * All rights reserved.
  *
  * This software is licensed under terms that can be found in the LICENSE file
  * in the root directory of this software component.
  * If no LICENSE file comes with this software, it is provided AS-IS.
  *
  ******************************************************************************
  */

/* Includes ------------------------------------------------------------------*/
#include "logging.h"
#include "main.h"
#include "ai_dpu.h"
#include "aiTestHelper_ST_AI.h"
#include "cpu_stats.h"
#include "ai_device_adaptor.h"

/* Private function prototypes -----------------------------------------------*/
static DPU_StatusTypeDef AiDPUCheckModel(stai_network_info *pxInfo);

STAI_NETWORK_CONTEXT_DECLARE(network, STAI_NETWORK_CONTEXT_SIZE)
static stai_ptr stai_inputs[STAI_NETWORK_OUT_NUM];
static stai_ptr stai_outputs[STAI_NETWORK_IN_NUM];
static stai_ptr activations[STAI_NETWORK_ACTIVATIONS_NUM];
// #define STAI_NETWORK_ACTIVATION_1_ALIGNMENT  (4) //issue with IAR
// STAI_ALIGNED(STAI_NETWORK_ACTIVATION_1_ALIGNMENT) 
STAI_ALIGNED(4)  
static uint8_t activations_1[STAI_NETWORK_ACTIVATION_1_SIZE_BYTES];


/* Exported Functions Definition -------------------------------------------- */
/**
 * @brief checks and loads AI model
 * @param pxInfo:  pointer to AI DPU context
 * @retval DPU_OK if success, DPU_ERROR else
 */
DPU_StatusTypeDef AiDPULoadModel(AIProcCtx_t * pxCtx)
{
  assert_param( NULL != pxCtx );
  stai_return_code stai_err;
  stai_size _dummy;

  pxCtx->p_network        = (stai_network *)network;
  pxCtx->p_stai_inputs    = stai_inputs;
  pxCtx->p_stai_outputs   = stai_outputs;
  pxCtx->p_activations    = activations;
  pxCtx->p_activations[0] = (stai_ptr) activations_1;

  pxCtx->sensor_type      = CTRL_X_CUBE_AI_SENSOR_TYPE;
  
  /* display AI platform version */
  stai_platform_version();
  
  /* Runtime initialization */
  stai_err = stai_runtime_init();
  
  /* -- Create and initialize the c-model */
  
  /* Initialize the instance */
  stai_err =  stai_network_init(pxCtx->p_network);
  if (STAI_SUCCESS != stai_err )
  {
    stai_log_err(stai_err, "stai_network_init");
    return DPU_ERROR;
  }
  
  stai_network_get_info(pxCtx->p_network, &pxCtx->info);
  
  if (DPU_OK != AiDPUCheckModel(&pxCtx->info))
  {
    LogError("AI_DPU: Check model Failed \n\r");
    Error_Handler();
  }
  
  /* -- Set the @ of the activation buffers                                   */
  /* Activation buffers are allocated in the user/app space                   */
  assert_param( 1 == STAI_NETWORK_ACTIVATIONS_NUM );
  
  stai_network_set_activations(pxCtx->p_network, pxCtx->p_activations, \
                                              STAI_NETWORK_ACTIVATIONS_NUM);
  if (STAI_SUCCESS != stai_err )
  {
    stai_log_err(stai_err, "stai_network_set_activations");
    return DPU_ERROR;
  }
  
  /* Set IO ----------------------------------------------------------------- */
  stai_network_get_inputs(pxCtx->p_network, pxCtx->p_stai_inputs, &_dummy);
  stai_network_get_outputs(pxCtx->p_network, pxCtx->p_stai_outputs, &_dummy);
  
  if ( STAI_FORMAT_S8 == pxCtx->info.inputs[0].format )
  {
    pxCtx->input_Q_inv_scale = 1/ pxCtx->info.inputs[0].scale.data[0];
    pxCtx->input_Q_offset = pxCtx->info.inputs[0].zeropoint.data[0];
  }

  assert_param ( 1 == pxCtx->info.n_inputs );  /* already checked in AiDPUCheckModel */
  assert_param ( 1 == pxCtx->info.n_outputs ); /* already checked in AiDPUCheckModel */
#if ( CTRL_X_CUBE_AI_PREPROC == CTRL_AI_GRAV_ROT_SUPPR || CTRL_X_CUBE_AI_PREPROC == CTRL_AI_GRAV_ROT) // work around to fix
  pxCtx->in_height  = pxCtx->info.inputs[0].shape.data[AI_DPU_WIDTH];
  pxCtx->in_width   = pxCtx->info.inputs[0].shape.data[AI_DPU_HEIGHT];
#else
  pxCtx->in_width   = pxCtx->info.inputs[0].shape.data[AI_DPU_WIDTH];
  pxCtx->in_height  = pxCtx->info.inputs[0].shape.data[AI_DPU_HEIGHT];
#endif

  pxCtx->out_height = pxCtx->info.outputs[0].shape.data[AI_DPU_HEIGHT];
  
  if ( COM_TYPE_ACC == pxCtx->sensor_type && 3 != pxCtx->in_width )
  {
    LogError("AiDPULoadModel: Accelero needs a width of 3 \n\r");
    return DPU_ERROR;
  }
  
  stai_log_network_infos(pxCtx->p_network);
  
  return DPU_OK;
}

/**
 * @brief Releases AI model
 * @param pxInfo:  pointer to AI DPU context
 * @retval DPU_OK if success, DPU_ERROR else
 */
DPU_StatusTypeDef AiDPUReleaseModel(AIProcCtx_t * pxCtx)
{
  assert_param( NULL != pxCtx );

  /* Deinitialize network model context */
  if ( STAI_SUCCESS != stai_network_deinit(pxCtx->p_network) )
  {
    LogError("AiDPUReleaseModel: network de-init failed \n\r");
    return DPU_ERROR;
  };

  /* Deinitialize runtime library */
  if ( STAI_SUCCESS != stai_runtime_deinit() )
  {
    LogError("AiDPUReleaseModel: STAI runtime de-init failed \n\r");
    return DPU_ERROR;
  };
  return DPU_OK;
}

/**
 * @brief Processes Data into AI model
 * @param pxInfo:  pointer to AI DPU context
 * @param pxInfo:  pointer to output array
 * @retval DPU_OK if success, DPU_ERROR else
 */
DPU_StatusTypeDef AiDPUProcess(AIProcCtx_t *pxCtx, float *p_out)
{
  assert_param( NULL != pxCtx );
  stai_return_code return_code;
  if ( p_out )
  {
    assert_param ( 1 == pxCtx->info.n_outputs );
    const stai_ptr outputs_ptr[] = { (void *) p_out };
    stai_network_set_outputs(pxCtx->p_network, outputs_ptr,1);
  }
  port_dwt_reset();
  return_code = stai_network_run(pxCtx->p_network, STAI_MODE_SYNC);
  if ( STAI_SUCCESS != return_code )
  {
    stai_log_err(return_code, "stai_network_run");
    return DPU_ERROR;
  }
  time_stats_store(TIME_STAT_AI_PROC,port_dwt_get_cycles()*1000.0F/port_hal_get_cpu_freq());
  return DPU_OK;
}

/* Private Functions Definition --------------------------------------------- */

/**
 * @brief Check if model can be supported by app
 * @param pxInfo:  pointer to network info
 * @retval DPU_OK if success, DPU_ERROR else
 */
static DPU_StatusTypeDef AiDPUCheckModel(stai_network_info *pxInfo)
{
  assert_param ( NULL != pxInfo );
  DPU_StatusTypeDef res = DPU_OK;

  if (pxInfo->api_version.major != AI_DPU_X_CUBE_AI_API_MAJOR ||\
      pxInfo->api_version.minor != AI_DPU_X_CUBE_AI_API_MINOR ||\
      pxInfo->api_version.micro != AI_DPU_X_CUBE_AI_API_MICRO)
  {
    LogError("AI_DPU: Incompatible AI API version \n\r");
    res = DPU_ERROR;
  }
  if (pxInfo->n_inputs > AI_DPU_NB_MAX_INPUT )
  {
    LogError("AI_DPU: Too many input tensors \n\r");
    res = DPU_ERROR;
  }
  if (pxInfo->n_outputs > AI_DPU_NB_MAX_OUTPUT )
  {
    LogError("AI_DPU: Too many output tensors\n\r");
    res = DPU_ERROR;
  }
  if (!(pxInfo->flags & STAI_FLAG_INPUTS) )
  {
    LogError("AI_DPU: --no-inputs-allocation not yet supported  \r\n");
    res = DPU_ERROR;
  }
  if (!(pxInfo->flags & STAI_FLAG_OUTPUTS) )
  {
    LogError("AI_DPU: --no-outputs-allocation not yet supported  \r\n");
    res = DPU_ERROR;
  }
  if (pxInfo->flags & STAI_FLAG_ACTIVATIONS)
  {
    LogWarn("AI_DPU: Activation are already allocated \r\n");
  }
  for (int i=0; i< pxInfo->n_inputs ; i++ )
  {
    if (STAI_FORMAT_S8 != pxInfo->inputs[i].format &&\
        STAI_FORMAT_FLOAT32 != pxInfo->inputs[i].format &&\
        4 != pxInfo->inputs[i].shape.size &&\
        !(pxInfo->inputs[i].flags & STAI_FLAG_CHANNEL_LAST) )
    {
      LogError("AI_DPU: Input format not supported\n\r");
      res = DPU_ERROR;
    }
  }
  for (int i=0; i< pxInfo->n_outputs ; i++ )
  {
    if (STAI_FORMAT_FLOAT32 != pxInfo->outputs[i].format &&\
        2 != pxInfo->outputs[i].shape.size)
    {
      LogError("AI_DPU: Output format not supported\n\r");
      res = DPU_ERROR;
    }
  }
  return res;
}
