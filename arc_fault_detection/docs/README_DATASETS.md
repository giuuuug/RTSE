

# Arc Fault Detection (AFD) Datasets

This document describes the datasets used for training, validating, and testing models in the Arc Fault Detection project. You can provide datasets as individual `.csv` files or as a `.zip` archive containing the CSVs. The pipeline will automatically extract and use CSVs from a provided ZIP file.

## Table of Contents

<details open><summary><a href="#1-dataset-structure-and-files"><b>1. Dataset Structure and Files</b></a></summary></details>
<details open><summary><a href="#2-data-format"><b>2. Data Format</b></a></summary></details>
<details open><summary><a href="#3-splitting-strategy"><b>3. Splitting Strategy</b></a></summary></details>
<details open><summary><a href="#4-preprocessing"><b>4. Preprocessing</b></a></summary></details>
<details open><summary><a href="#5-representative-set-for-quantization"><b>5. Representative Set for Quantization</b></a></summary></details>
<details open><summary><a href="#6-quality-checks"><b>6. Quality Checks</b></a></summary></details>
<details open><summary><a href="#7-best-practices"><b>7. Best Practices</b></a></summary></details>
<details open><summary><a href="#8-troubleshooting"><b>8. Troubleshooting</b></a></summary></details>

---

<details open><summary><a href="#1-dataset-structure-and-files"><b>1. Dataset Structure and Files</b></a></summary><a id="1-dataset-structure-and-files"></a>

All datasets are located in:  
`arc_fault_detection/datasets/afd_test_bench/`

- **Arc_and_Normal_train.csv**: Training set, contains both Arc and Normal samples.
- **Arc_and_Normal_val.csv**: Validation set, contains both Arc and Normal samples.
- **Arc_and_Normal_test.csv**: Test set, contains both Arc and Normal samples.
- **20Arc_20Normal_predict.csv**: For prediction or demo purposes, contains a mix of Arc and Normal samples.

</details>


<details open><summary><a href="#2-data-format"><b>2. Data Format</b></a></summary><a id="2-data-format"></a>

- Each CSV row:  
  `[feature_1, feature_2, ..., feature_N, label]`
- Features: Raw time-domain samples or derived features.
- Label:  
  - `0` = Normal  
  - `1` = Arc

</details>



<details open><summary><a href="#3-splitting-strategy"><b>3. Splitting Strategy</b></a></summary><a id="3-splitting-strategy"></a>

- **Train**: ~70%
- **Validation**: ~15%
- **Test**: ~15%
- Splits are stratified to preserve class balance.
- Do not mix test data into training or quantization.

**Automatic split:**
- If either the validation or test set is not provided, it will be automatically generated by splitting the training set according to the configured proportions.

</details>


<details open><summary><a href="#4-preprocessing"><b>4. Preprocessing</b></a></summary><a id="4-preprocessing"></a>

- Downsampling, normalization, and the time-domain/frequency-domain switch are configurable in your YAML config.
- Example (matching the reference configuration):
  ```yaml
  preprocessing:
    downsampling: False
    normalization: True
    time_domain: False
  ```
- Preprocessing must be consistent across training, evaluation, quantization, prediction, and benchmarking.

</details>


<details open><summary><a href="#5-representative-set-for-quantization"><b>5. Representative Set for Quantization</b></a></summary><a id="5-representative-set-for-quantization"></a>

- If `quantization_path` is not provided, a stratified subset of the training set can be used (e.g., by setting `quantization_split`).
- Aim for 200â€“1000 diverse samples for int8 calibration.
- Do not use test data for quantization.

</details>


<details open><summary><a href="#6-quality-checks"><b>6. Quality Checks</b></a></summary><a id="6-quality-checks"></a>

- No NaN or Inf values.
- Consistent row length.
- Labels only in `{0, 1}`.
- Visualize and compare Arc vs Normal waveforms.

</details>


<details open><summary><a href="#7-best-practices"><b>7. Best Practices</b></a></summary><a id="7-best-practices"></a>

- Use a fixed random seed for reproducible splits.
- Keep the test set fully isolated.
- Document any preprocessing changes.
- Maintain a validation set to monitor overfitting.

</details>


<details open><summary><a href="#8-troubleshooting"><b>8. Troubleshooting</b></a></summary><a id="8-troubleshooting"></a>

| Issue                        | Likely Cause                        | Action                                 |
|------------------------------|-------------------------------------|----------------------------------------|
| Arc recall drop              | Arc class underrepresented          | Add Arc samples    |
| Overfitting                  | Small or non-representative training set    | Collect more data, regularize          |
| Quantization accuracy loss   | non-representative dataset (too small, with outliers, ...)      | diversity of set avoiding non representative data     |
| CSV read errors              | Format or encoding mismatch         | Check delimiter, encoding, headers     |
| Model shape mismatch         | Variable or short sequence length            | check downsampling                    |


</details>

---

**Summary:**  
- Use the provided CSVs for training, validation, and testing.
- Ensure consistent preprocessing and splitting.
- Perform quality checks before training and quantization.
- Maintain reproducibility for STM32 deployment.

---
