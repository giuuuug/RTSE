general:
  project_name: aed_project
  logs_dir: logs
  saved_models_dir: saved_models
  global_seed: 120
  gpu_memory_limit: 5
  display_figures: True 


operation_mode: quantization 
#choices=['training' , 'evaluation', 'prediction', 'deployment', 'quantization', 'benchmarking',
#        'chain_tqeb','chain_tqe',' chain_eqe','chain_qb','chain_eqeb','chain_qd ']

model: 
  model_path: ../../stm32ai-modelzoo/audio_event_detection/yamnet/ST_pretrainedmodel_public_dataset/esc10/yamnet_e1024_64x96_tl/yamnet_e1024_64x96_tl_float.onnx
    # Change this path to the model you wish to use
dataset:
  dataset_name: esc10
  class_names: ['dog', 'chainsaw', 'crackling_fire', 'helicopter', 'rain', 'crying_baby', 'clock_tick', 'sneezing', 'rooster', 'sea_waves']
  file_extension: '.wav'
  quantization_audio_path: ./datasets/ESC-50/audio 
  quantization_csv_path: ./datasets/ESC-50/meta/esc50.csv
  quantization_split:  # Optional

  multi_label: False 
  use_garbage_class: False 
  n_samples_per_garbage_class: 2
  seed: 120 # Optional, there is a default seed
  to_cache: True
  shuffle: True

preprocessing:
  min_length: 1
  max_length : 10
  target_rate: 16000
  top_db: 60
  frame_length: 3200
  hop_length: 3200
  trim_last_second: False
  lengthen : 'after'

feature_extraction:
  patch_length: 96
  n_mels: 64
  overlap: 0.25
  n_fft: 512
  hop_length: 160
  window_length: 400
  window: hann
  center: False
  pad_mode: constant
  power: 1.0
  fmin: 125
  fmax: 7500
  norm: None
  htk : True
  to_db : False

quantization:
  quantizer: onnx_quantizer  # TFlite_converter for TFLite quantization or onnx_quantizer for ONNX quantization
  quantization_type: PTQ
  quantization_input_type: int8
  quantization_output_type: float
  granularity: per_channel          # Optional, defaults to "per_channel". 
  # optimize: True                     # Optional, defaults to False.
  # target_opset: 17                   # Optional, defaults to 17. Only used for ONNX quantization
  onnx_extra_options: 
    CalibMovingAverage: True
  onnx_quant_parameters:
    op_types_to_quantize: ["Conv", "Relu", "Squeeze", "GlobalAveragePool", "Gemm", "Transpose"] #All except softmax to preserve float output. Transpose probably unnecessary.
  export_dir: quantized_models


mlflow:
  uri: ./tf/src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./tf/src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}