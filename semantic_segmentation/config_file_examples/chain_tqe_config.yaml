general:
  project_name: segmentation
  saved_models_dir: saved_models
  gpu_memory_limit: 12
  global_seed: 127
  display_figures: False

model:
  model_type: deeplab
  model_name: st_deeplabv3_mnv2_a050_s16_asppv2
  input_shape: (320, 320, 3)

operation_mode: chain_tqe

dataset:
  dataset_name: person_coco_2017_pascal_voc_2012
  class_names: ["background", "person"]
  training_path: ./datasets/person_COCO2017_VOC2012/JPEGImages
  training_masks_path: ./datasets/person_COCO2017_VOC2012/SegmentationClassAug
  training_files_path: ./datasets/person_COCO2017_VOC2012/ImageSets/Segmentation/trainaug.txt
  validation_path: ./datasets/person_COCO2017_VOC2012/JPEGImages
  validation_masks_path: ./datasets/person_COCO2017_VOC2012/SegmentationClassAug
  validation_files_path: ./datasets/person_COCO2017_VOC2012/ImageSets/Segmentation/val.txt
  quantization_split : 0.05
  
preprocessing:
  rescaling: {scale: 1/127.5, offset: -1}
  resizing:
    aspect_ratio: fit
    interpolation: bilinear 
  color_mode: rgb

data_augmentation:
  random_flip:
    mode: horizontal_and_vertical
  random_contrast:
    factor: 0.4
  random_brightness:
    factor: 0.3
    
training:
  dropout: 0.6
  batch_size: 16
  epochs: 1
  optimizer:
    Adam:
      learning_rate: 0.005
  callbacks:          
    ReduceLROnPlateau:
      monitor: val_accuracy
      mode: max
      factor: 0.5
      patience: 40
      min_lr: 1.0e-05
    EarlyStopping:
      monitor: val_accuracy
      mode: max
      restore_best_weights: true
      patience: 60
      
quantization:
   quantizer: TFlite_converter
   quantization_type: PTQ
   quantization_input_type: uint8
   quantization_output_type: float
   export_dir: quantized_models

mlflow:
  uri: ./tf/src/experiments_outputs/mlruns

hydra:
  run:
    dir: ./tf/src/experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}